{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "import numpy as np\n",
    "import sklearn.datasets\n",
    "import sklearn.model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--test_size'], dest='test_size', nargs=None, const=None, default=0.1, type=<function <lambda> at 0x138d319e0>, choices=None, required=False, help='Test size', metavar=None)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "# These arguments will be set appropriately by ReCodEx, even if you change them.\n",
    "parser.add_argument(\"--recodex\", default=False, action=\"store_true\", help=\"Running in ReCodEx\")\n",
    "parser.add_argument(\"--seed\", default=42, type=int, help=\"Random seed\")\n",
    "parser.add_argument(\"--test_size\", default=0.1, type=lambda x: int(x) if x.isdigit() else float(x), help=\"Test size\")\n",
    "# If you add more arguments, ReCodEx will keep them with your default values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = sklearn.datasets.load_diabetes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _diabetes_dataset:\n",
      "\n",
      "Diabetes dataset\n",
      "----------------\n",
      "\n",
      "Ten baseline variables, age, sex, body mass index, average blood\n",
      "pressure, and six blood serum measurements were obtained for each of n =\n",
      "442 diabetes patients, as well as the response of interest, a\n",
      "quantitative measure of disease progression one year after baseline.\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      ":Number of Instances: 442\n",
      "\n",
      ":Number of Attributes: First 10 columns are numeric predictive values\n",
      "\n",
      ":Target: Column 11 is a quantitative measure of disease progression one year after baseline\n",
      "\n",
      ":Attribute Information:\n",
      "    - age     age in years\n",
      "    - sex\n",
      "    - bmi     body mass index\n",
      "    - bp      average blood pressure\n",
      "    - s1      tc, total serum cholesterol\n",
      "    - s2      ldl, low-density lipoproteins\n",
      "    - s3      hdl, high-density lipoproteins\n",
      "    - s4      tch, total cholesterol / HDL\n",
      "    - s5      ltg, possibly log of serum triglycerides level\n",
      "    - s6      glu, blood sugar level\n",
      "\n",
      "Note: Each of these 10 feature variables have been mean centered and scaled by the standard deviation times the square root of `n_samples` (i.e. the sum of squares of each column totals 1).\n",
      "\n",
      "Source URL:\n",
      "https://www4.stat.ncsu.edu/~boos/var.select/diabetes.html\n",
      "\n",
      "For more information see:\n",
      "Bradley Efron, Trevor Hastie, Iain Johnstone and Robert Tibshirani (2004) \"Least Angle Regression,\" Annals of Statistics (with discussion), 407-499.\n",
      "(https://web.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(dataset.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        age       sex       bmi        bp        s1        s2        s3  \\\n",
      "0  0.038076  0.050680  0.061696  0.021872 -0.044223 -0.034821 -0.043401   \n",
      "1 -0.001882 -0.044642 -0.051474 -0.026328 -0.008449 -0.019163  0.074412   \n",
      "2  0.085299  0.050680  0.044451 -0.005670 -0.045599 -0.034194 -0.032356   \n",
      "3 -0.089063 -0.044642 -0.011595 -0.036656  0.012191  0.024991 -0.036038   \n",
      "4  0.005383 -0.044642 -0.036385  0.021872  0.003935  0.015596  0.008142   \n",
      "\n",
      "         s4        s5        s6  bias  \n",
      "0 -0.002592  0.019907 -0.017646     1  \n",
      "1 -0.039493 -0.068332 -0.092204     1  \n",
      "2 -0.002592  0.002861 -0.025930     1  \n",
      "3  0.034309  0.022688 -0.009362     1  \n",
      "4 -0.002592 -0.031988 -0.046641     1  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Convert the dataset to a DataFrame\n",
    "df = pd.DataFrame(data=dataset.data, columns=dataset.feature_names)\n",
    "df['bias'] = 1\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.03807591  0.05068012  0.06169621 ...  0.01990749 -0.01764613\n",
      "   1.        ]\n",
      " [-0.00188202 -0.04464164 -0.05147406 ... -0.06833155 -0.09220405\n",
      "   1.        ]\n",
      " [ 0.08529891  0.05068012  0.04445121 ...  0.00286131 -0.02593034\n",
      "   1.        ]\n",
      " ...\n",
      " [ 0.04170844  0.05068012 -0.01590626 ... -0.04688253  0.01549073\n",
      "   1.        ]\n",
      " [-0.04547248 -0.04464164  0.03906215 ...  0.04452873 -0.02593034\n",
      "   1.        ]\n",
      " [-0.04547248 -0.04464164 -0.0730303  ... -0.00422151  0.00306441\n",
      "   1.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(df.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.target = dataset.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'args' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Split the dataset into a train set and a test set\u001b[39;00m\n\u001b[1;32m      2\u001b[0m X_train, X_test, target_train, target_test \u001b[38;5;241m=\u001b[39m sklearn\u001b[38;5;241m.\u001b[39mmodel_selection\u001b[38;5;241m.\u001b[39mtrain_test_split(\n\u001b[1;32m      3\u001b[0m     df\u001b[38;5;241m.\u001b[39mvalues,  \u001b[38;5;66;03m# Input data (including the bias column)\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     df\u001b[38;5;241m.\u001b[39mtarget,          \u001b[38;5;66;03m# Target values\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m     test_size \u001b[38;5;241m=\u001b[39m \u001b[43margs\u001b[49m\u001b[38;5;241m.\u001b[39mtest_size,   \u001b[38;5;66;03m# Use test_size from the argument parser\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     random_state \u001b[38;5;241m=\u001b[39m args\u001b[38;5;241m.\u001b[39mseed      \u001b[38;5;66;03m# Set random_state for reproducibility\u001b[39;00m\n\u001b[1;32m      7\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'args' is not defined"
     ]
    }
   ],
   "source": [
    "# Split the dataset into a train set and a test set\n",
    "X_train, X_test, target_train, target_test = sklearn.model_selection.train_test_split(\n",
    "    df.values,  # Input data (including the bias column)\n",
    "    df.target,          # Target values\n",
    "    test_size = args.test_size,   # Use test_size from the argument parser\n",
    "    random_state = args.seed      # Set random_state for reproducibility\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = np.linalg.inv(X_train.T @ X_train) @ X_train.T @ target_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = X_test @ W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(np.mean((predict - target_test)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.datasets\n",
    "import sklearn.model_selection\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "# These arguments will be set appropriately by ReCodEx, even if you change them.\n",
    "parser.add_argument(\"--recodex\", default=False, action=\"store_true\", help=\"Running in ReCodEx\")\n",
    "parser.add_argument(\"--seed\", default=42, type=int, help=\"Random seed\")\n",
    "parser.add_argument(\"--test_size\", default=0.1, type=lambda x: int(x) if x.isdigit() else float(x), help=\"Test size\")\n",
    "# If you add more arguments, ReCodEx will keep them with your default values.\n",
    "\n",
    "\n",
    "def main(args: argparse.Namespace) -> float:\n",
    "    # Load the diabetes dataset.\n",
    "    dataset = sklearn.datasets.load_diabetes()\n",
    "\n",
    "    # The input data are in `dataset.data`, targets are in `dataset.target`.\n",
    "\n",
    "    # If you want to learn about the dataset, you can print some information\n",
    "    # about it using `print(dataset.DESCR)`.\n",
    "\n",
    "    # TODO: Append a constant feature with value 1 to the end of every input data.\n",
    "    # Then we do not need to explicitly represent bias - it becomes the last weight.\n",
    "    # Convert the dataset to a DataFrame\n",
    "    df = pd.DataFrame(data=dataset.data, columns=dataset.feature_names)\n",
    "    df['bias'] = 1\n",
    "    # TODO: Split the dataset into a train set and a test set.\n",
    "    # Use `sklearn.model_selection.train_test_split` method call, passing\n",
    "    # arguments `test_size=args.test_size, random_state=args.seed`.\n",
    "    df.target = dataset.target\n",
    "    X_train, X_test, target_train, target_test = sklearn.model_selection.train_test_split(\n",
    "    df.values,  # Input data (including the bias column)\n",
    "    df.target,          # Target values\n",
    "    test_size = args.test_size,   # Use test_size from the argument parser\n",
    "    random_state = args.seed      # Set random_state for reproducibility\n",
    "    )\n",
    "    # TODO: Solve the linear regression using the algorithm from the lecture,\n",
    "    # explicitly computing the matrix inverse (using `np.linalg.inv`).\n",
    "    W = np.linalg.inv(X_train.T @ X_train) @ X_train.T @ target_train\n",
    "    # TODO: Predict target values on the test set.\n",
    "    predict = X_test @ W\n",
    "    # TODO: Manually compute root mean square error on the test set predictions.\n",
    "    rmse = np.sqrt(np.mean((predict - target_test)**2))\n",
    "\n",
    "    return rmse"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
